## 4. 技術アーキテクチャ

### 4.1 技術スタック詳細

```
┌─────────────────────────────────────────────────────────────┐
│                    フロントエンド                              │
│  React Native (TypeScript)                                   │
│  - iOS/iPadOS 26以降対応                                      │
│  - @react-native-ai/apple（Callstack製）                     │
│    → Apple SpeechAnalyzer APIをラップしたNative Module       │
│    → Swiftを直接書く必要なし、TypeScriptのみで完結            │
│  - Supabase Realtime連携                                     │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                 音声処理パイプライン                           │
│                                                              │
│  ① Apple SpeechAnalyzer（文字起こし）                         │
│     - 完全オンデバイス処理（無料・無制限）                       │
│     - 長時間音声対応（講義・会議・会話に最適化）                  │
│     - Whisper比2.2倍高速（MacStories実測）                    │
│     - iOS 26で新規導入（WWDC 2025発表）                       │
│                                                              │
│  ② 話者分離（以下から選択）                                    │
│                                                              │
│     【推奨】pyannote.audio（オープンソース）                   │
│     - MIT License（商用利用可、無料）                          │
│     - 言語非依存（音声特徴量ベース、日本語高精度）                │
│     - セルフホスト or pyannoteAI API                         │
│     - 1時間音声 → 約1.5分処理（V100 GPU）                     │
│     - 140,000+開発者が利用                                    │
│                                                              │
│     【代替】AssemblyAI Universal                             │
│     - 99言語対応、日本語高精度                                  │
│     - 話者分離が基本料金に含まれる（追加料金なし）                │
│     - $0.27/時間（約40円/時間）                                │
│     - フルマネージドで運用負荷低                                │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    AI分析エンジン                              │
│                                                              │
│  Claude Sonnet 4.5（Anthropic）                              │
│  - 入力: 100万トークンあたり$3、出力: 100万トークンあたり$15     │
│  - Batch API利用で50%割引可能                                 │
│  - Prompt Caching利用で最大90%削減可能                        │
│  - SWE-bench 77.2%達成、最高精度のコーディング性能               │
│  - 2025年9月29日リリース                                      │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    データ基盤                                 │
│                                                              │
│  Supabase                                                    │
│  - PostgreSQL（メインDB）                                     │
│  - Realtime Subscriptions（リアルタイム同期）                   │
│  - Edge Functions（Deno）                                    │
│  - Storage（音声ファイル一時保存）                              │
│  - Row Level Security（店舗ごとデータ分離）                     │
│  - Pro Plan: $25/月～                                        │
│                                                              │
│  Qdrant Cloud                                                │
│  - ベクトル類似検索（成功事例マッチング）                        │
│  - セルフホストまたはCloud（$95/月～）                          │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│           話者分離サーバー（pyannote.audio選択時）              │
│                                                              │
│  【推奨スペック】                                               │
│  - GPU: RTX 3060/4060以上（VRAM 6-8GB）                       │
│  - RAM: 16GB                                                  │
│  - OS: Ubuntu 22.04                                          │
│  - 処理速度: 1時間音声 → 約2-4分                               │
│                                                              │
│  【インフラ選択肢】                                             │
│  - セルフホスト（オンプレミス/VPS）                             │
│  - VAST.ai（GPU時間課金：$0.15-0.30/h）                       │
│  - AWS g4dn.xlarge（T4 GPU）                                 │
│  - pyannoteAI API（フルマネージド）                            │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    インフラ                                   │
│                                                              │
│  Vercel（フロントエンドホスティング）                           │
│  - Pro Plan: $20/月                                          │
│  - 自動スケーリング、エッジ配信                                 │
└─────────────────────────────────────────────────────────────┘
```

### 4.2 Apple SpeechAnalyzer詳細

**出典：Apple Developer Documentation、WWDC 2025 Session 277**

iOS 26で導入された**SpeechAnalyzer**は、従来のSFSpeechRecognizer（iOS 10〜）を完全に置き換える次世代音声認識APIです。

| 項目 | 旧API (SFSpeechRecognizer) | 新API (SpeechAnalyzer) |
|------|---------------------------|------------------------|
| 対応用途 | 短文ディクテーション | 長時間会話・講義・会議 |
| 処理方式 | サーバー依存（一部） | **完全オンデバイス** |
| 言語管理 | ユーザーが手動設定 | **自動管理** |
| 遠距離音声 | 非対応 | **対応** |
| リアルタイム精度 | 標準 | **大幅改善** |

**パフォーマンス比較**（MacStories実測、M4 Mac mini）：

| 処理 | SpeechAnalyzer | Whisper Large V3 Turbo | 比較 |
|------|---------------|------------------------|------|
| 34分動画の文字起こし | **45秒** | 1分41秒 | **2.2倍高速** |
| 精度 | 同等 | 同等 | 差なし |

#### React Nativeからの利用方法

**@react-native-ai/apple**（Callstack製）を利用することで、**Swiftを直接書く必要なく、TypeScriptのみで完結**できます。

**出典：Callstack Blog「On-Device Speech Transcription with Apple SpeechAnalyzer and AI SDK」（2025年8月7日）**

| 項目 | 詳細 |
|------|------|
| パッケージ名 | `@react-native-ai/apple` |
| 開発元 | Callstack（React Native公式パートナー） |
| 実装方式 | Native Module（Swift/Objective-Cをラップ） |
| 開発言語 | **TypeScriptのみで完結** |
| 言語モデル | システムアセットカタログに保存（アプリサイズ影響ゼロ） |
| AI SDK連携 | Vercel AI SDK `experimental_transcribe` 対応 |

```typescript
// React NativeからApple SpeechAnalyzerを使用
// @react-native-ai/appleパッケージ（Callstack製）を利用
// ※ Swiftを直接書く必要なし、TypeScriptのみで完結

import { experimental_transcribe as transcribe } from 'ai';
import { apple, NativeAppleSpeech } from '@react-native-ai/apple';

// 日本語モデルを事前ダウンロード（初回のみ）
// システム全体のアセットカタログに保存されるため、アプリサイズへの影響ゼロ
await NativeAppleSpeech.prepare('ja');

// 音声ファイルの文字起こし
const audioFile = await fetch('file:///path/to/audio.wav');
const audioBuffer = await audioFile.arrayBuffer();

const { text, segments, durationInSeconds } = await transcribe({
  model: apple.transcriptionModel(),
  audio: audioBuffer,
  providerOptions: {
    apple: {
      language: 'ja'  // 日本語を指定
    }
  }
});

// 結果例
console.log(text);
// "今日はどんな感じにしますか"

console.log(segments);
// [
//   { text: '今日は', startTime: 0.1, endTime: 0.4 },
//   { text: 'どんな', startTime: 0.4, endTime: 0.7 },
//   { text: '感じに', startTime: 0.7, endTime: 1.0 },
//   { text: 'しますか', startTime: 1.0, endTime: 1.5 }
// ]

// Supabaseにストリーミング保存
for (const segment of segments) {
  await supabase.from('transcripts').insert({
    session_id: sessionId,
    chunk_index: chunkIndex,
    text: segment.text,
    start_time_ms: Math.round(segment.startTime * 1000),
    end_time_ms: Math.round(segment.endTime * 1000)
  });
}
```

### 4.3 話者分離アーキテクチャ

話者分離（Speaker Diarization）には2つの選択肢を用意。要件に応じて選択可能。

#### 4.3.1 話者分離オプション比較

| 項目 | **pyannote.audio（推奨）** | AssemblyAI |
|------|---------------------------|------------|
| **ライセンス** | MIT（オープンソース） | プロプライエタリ |
| **処理方式** | セルフホスト or API | API |
| **言語対応** | 言語非依存（音声特徴量ベース） | 99言語 |
| **日本語精度** | ◎ 高精度（検証済み） | ◎ 高精度 |
| **処理速度** | 1時間音声 → 約1.5分（V100 GPU） | 1時間音声 → 約3-5分 |
| **コスト（100h/月）** | **0〜3,000円**（セルフホスト/API） | **4,050円** |
| **利用者数** | 140,000+開発者 | 多数 |
| **運用負荷** | 中（サーバー管理必要） | 低（フルマネージド） |

**出典：**
- pyannote.audio GitHub: https://github.com/pyannote/pyannote-audio
- pyannoteAI Pricing: https://www.pyannote.ai/pricing
- Hugging Face Model Card: pyannote/speaker-diarization-community-1

#### 4.3.2 pyannote.audio 詳細（推奨オプション）

**pyannote.audio**は、話者分離のためのPythonによるオープンソースフレームワークです。PyTorch機械学習フレームワークに基づいており、MIT Licenseで商用利用可能です。

**特徴：**
- **言語非依存**: 音声特徴量ベースのため、日本語を含むあらゆる言語に対応
- **高精度**: 最新のcommunity-1モデルで大幅な精度向上
- **柔軟な導入**: セルフホスト/pyannoteAI API/VAST.aiなど複数の選択肢
- **コスト効率**: セルフホストなら変動費ゼロ

##### iPad上での実行について

**結論：iPadでのオンデバイス実行は不可。サーバー処理が必須。**

pyannote.audioはPython + PyTorchベースであり、iOS/iPad向けのCore ML変換は公式サポートされていません。そのため、話者分離処理は専用サーバーで実行し、結果をiPadに返す構成となります。

##### セルフホストサーバー推奨スペック

**出典：VAST.ai「Speaker Diarization with Pyannote on VAST」（2025年4月）**

| 項目 | 推奨スペック | 備考 |
|------|------------|------|
| **GPU** | RTX 3060/4060以上 | VRAM 6-8GB |
| **RAM** | 16GB | 音声ファイル処理用 |
| **CUDA** | 11.0+ | GPU利用時必須 |
| **OS** | Ubuntu 22.04 | Windows非公式 |
| **Python** | 3.8+ | PyTorch依存 |

**処理速度ベンチマーク（1時間音声の処理時間）：**

| ハードウェア | 処理時間 | Real-time factor |
|-------------|---------|------------------|
| **Tesla V100** | **約1.5分** | 2.5% |
| **T4 GPU (Colab/AWS)** | 約4分 | 6.7% |
| **M1 Mac (MPS)** | 約34秒（短い音声） | 高速 |
| **CPU（非推奨）** | 約30分 | 50% |

##### pyannote.audio セルフホスト実装

```python
# pyannote_server.py - FastAPI + pyannote.audio サーバー
from fastapi import FastAPI, UploadFile, File, BackgroundTasks
from pyannote.audio import Pipeline
import torch
import tempfile
import os
from supabase import create_client

app = FastAPI()

# pyannote.audio パイプライン初期化（起動時に1回のみ）
# Hugging Face Token必須（無料）
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-community-1",  # 最新モデル
    token=os.environ["HUGGINGFACE_TOKEN"]
)

# GPU使用（利用可能な場合）
if torch.cuda.is_available():
    pipeline.to(torch.device("cuda"))
    print("Using GPU for speaker diarization")
else:
    print("Warning: Running on CPU (slow)")

# Supabaseクライアント
supabase = create_client(
    os.environ["SUPABASE_URL"],
    os.environ["SUPABASE_KEY"]
)

@app.post("/diarize/{session_id}")
async def diarize_audio(
    session_id: str,
    audio: UploadFile = File(...),
    background_tasks: BackgroundTasks = None
):
    """音声ファイルの話者分離を実行"""
    
    # 一時ファイルに保存
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        content = await audio.read()
        tmp.write(content)
        tmp_path = tmp.name
    
    # バックグラウンドで処理（即座にレスポンス返却）
    background_tasks.add_task(
        process_diarization,
        tmp_path,
        session_id
    )
    
    return {"status": "processing", "session_id": session_id}

async def process_diarization(audio_path: str, session_id: str):
    """話者分離処理（バックグラウンド実行）"""
    try:
        # 話者分離実行（美容師 + お客様 = 2名）
        diarization = pipeline(audio_path, num_speakers=2)
        
        # 話者ごとの発話時間を集計
        speaker_durations = {}
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            duration = turn.end - turn.start
            speaker_durations[speaker] = speaker_durations.get(speaker, 0) + duration
        
        # 発話量が多い方を美容師と推定
        sorted_speakers = sorted(
            speaker_durations.items(),
            key=lambda x: x[1],
            reverse=True
        )
        role_mapping = {
            sorted_speakers[0][0]: "stylist",   # 発話多い = 美容師
            sorted_speakers[1][0]: "customer"   # 発話少ない = お客様
        }
        
        # 結果をSupabaseに保存
        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                "session_id": session_id,
                "chunk_index": chunk_index,
                "speaker": role_mapping[speaker],  # 'stylist' | 'customer' | 'unknown'
                "text": "",  # 後でtranscriptsとマージ
                "start_time_ms": int(turn.start * 1000),
                "end_time_ms": int(turn.end * 1000),
            })

        supabase.table("speaker_segments").insert(segments).execute()
        
        # ステータス更新
        supabase.table("sessions").update({
            "diarization_status": "completed"
        }).eq("id", session_id).execute()
        
    except Exception as e:
        supabase.table("sessions").update({
            "diarization_status": "failed",
            "error_message": str(e)
        }).eq("id", session_id).execute()
    finally:
        # 一時ファイル削除
        os.unlink(audio_path)

# 起動コマンド: uvicorn pyannote_server:app --host 0.0.0.0 --port 8000
```

##### pyannoteAI API 利用オプション

インフラ管理が不要な場合は、pyannoteAI のマネージドAPIも利用可能。

**pyannoteAI 料金体系（2025年最新）：**

| プラン | 月額 | 含まれる時間 | 超過料金 |
|--------|------|-------------|----------|
| **Free Trial** | 無料 | 150時間 | - |
| **Developer** | €19（約3,000円） | 125時間 | €0.14/h（約22円/h） |
| **Starter** | €99（約16,000円） | 825時間 | €0.12/h（約19円/h） |
| **Enterprise** | カスタム | 無制限 | カスタム |

```python
# pyannoteAI API利用時の実装（セルフホスト不要）
from pyannote.audio import Pipeline

# pyannoteAI APIキーで初期化（クラウド実行）
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-precision-2",  # プレミアムモデル
    token="PYANNOTEAI_API_KEY"
)

# APIに送信して処理（サーバー不要）
output = pipeline("audio.wav")  # pyannoteAIサーバーで処理

for turn, speaker in output.speaker_diarization:
    print(f"{speaker} speaks between t={turn.start:.1f}s and t={turn.end:.1f}s")
```

#### 4.3.3 AssemblyAI オプション（代替案）

運用負荷を最小化したい場合は、AssemblyAI Universalも選択可能。**話者分離が基本料金に含まれる**ため、追加コストなしで利用可能。

**出典：**
- AssemblyAI 料金: https://www.assemblyai.com/pricing
- AssemblyAI 話者分離: https://www.assemblyai.com/speaker-diarization

```typescript
// Supabase Edge Function: AssemblyAI話者分離処理
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';

serve(async (req) => {
  const { audioPath, sessionId } = await req.json();
  
  // Supabase Storageから音声取得
  const { data: audioData } = await supabase.storage
    .from('audio-chunks')
    .download(audioPath);
  
  // AssemblyAI APIで話者分離
  const response = await fetch('https://api.assemblyai.com/v2/transcript', {
    method: 'POST',
    headers: {
      'Authorization': ASSEMBLYAI_API_KEY,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      audio_url: await uploadToTemporaryUrl(audioData),
      speaker_labels: true,      // 話者分離有効化（追加料金なし）
      speakers_expected: 2,       // 美容師 + お客様
      language_code: 'ja'
    })
  });
  
  // ポーリングで結果取得
  const { id: transcriptId } = await response.json();
  let result;
  do {
    await new Promise(resolve => setTimeout(resolve, 1000));
    const statusResponse = await fetch(
      `https://api.assemblyai.com/v2/transcript/${transcriptId}`,
      { headers: { 'Authorization': ASSEMBLYAI_API_KEY } }
    );
    result = await statusResponse.json();
  } while (result.status !== 'completed');
  
  // 話者ラベル（A, B）を役割に変換
  const speakerStats = analyzeSpeakerRatio(result.utterances);
  const roleMapping = determinRoles(speakerStats);
  
  // 結果をSupabaseに保存
  for (const utterance of result.utterances) {
    await supabase.from('speaker_segments').insert({
      session_id: sessionId,
      role: roleMapping[utterance.speaker],
      text: utterance.text,
      start_time: utterance.start,
      end_time: utterance.end,
      confidence: utterance.confidence
    });
  }
  
  return new Response('OK', { status: 200 });
});
```

#### 4.3.4 話者分離コスト比較（100時間/月の場合）

| 方式 | 月額コスト | 初期投資 | 運用負荷 | 推奨用途 |
|------|-----------|---------|---------|---------|
| **pyannote セルフホスト** | **0円**（+インフラ5,000〜15,000円） | GPU VPS or サーバー | 中 | コスト重視・大規模 |
| **pyannoteAI Developer** | **約3,000円** | なし | 低 | 初期版・小規模 |
| **pyannoteAI Starter** | **約16,000円** | なし | 低 | 中規模 |
| **AssemblyAI** | **約4,050円** | なし | 低 | 文字起こし統合時 |

**推奨：**
- **第1フェーズ（初期版）**: pyannoteAI Developer（€19/月）で検証
- **第2フェーズ（スケール）**: セルフホストに移行してコスト削減

### 4.4 AI分析エンジン

Claude Sonnet 4.5を使用した科学的トーク分析：

```typescript
// セッション終了後の詳細分析
async function analyzeSession(sessionId: string): Promise<SessionReport> {
  // Supabaseから会話データ取得
  const { data: segments } = await supabase
    .from('speaker_segments')
    .select('*')
    .eq('session_id', sessionId)
    .order('start_time_ms');

  // 会話をフォーマット
  const conversation = segments.map(s =>
    `[${s.speaker === 'stylist' ? '美容師' : 'お客様'}] ${s.text}`
  ).join('\n');
  
  // Claude Sonnet 4.5で分析
  const analysis = await anthropic.messages.create({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 4096,
    messages: [{
      role: "user",
      content: `
あなたは美容室の接客コーチングの専門家です。
以下の美容師とお客様の会話を分析し、JSON形式でレポートを作成してください。

## 会話記録
${conversation}

## 分析項目（7つの科学的指標）

1. **トーク比率**
   - 美容師とお客様の発話時間比率を計算
   - 理想値: 美容師40% : お客様60%
   - 判定: 傾聴重視か、美容師主導か

2. **質問分析**
   - 質問数をカウント（理想: 8〜12回/施術）
   - オープン質問 vs クローズド質問の比率
   - 理想: オープン質問60%以上

3. **お客様感情分析**
   - 肯定的キーワード vs 否定的キーワードの比率
   - 理想: 肯定的70%以上
   - 検出キーワード例: いいですね、嬉しい、困る、嫌

4. **悩みキーワード検出**
   - お客様が発した髪の悩みに関するキーワード
   - 例: 乾燥、広がる、パサつく、うねり、白髪、薄毛

5. **提案タイミング分析**
   - 悩みキーワード検出から提案までの時間
   - 理想: 2〜5分以内

6. **提案品質分析**
   - ベネフィット提示型 vs スペック説明型
   - 理想: ベネフィット提示70%以上
   - ベネフィット例: 「朝のスタイリングが3分短縮」
   - スペック例: 「○○成分配合」

7. **成約判定**
   - 店販商品の購入有無を会話から推定
   - 購入意思表示のキーワード検出

## 出力形式
以下のJSON形式で出力してください：

{
  "talk_ratio": {
    "stylist_percent": number,
    "customer_percent": number,
    "judgment": "excellent" | "good" | "needs_improvement",
    "comment": string
  },
  "questions": {
    "total_count": number,
    "open_ratio": number,
    "judgment": "excellent" | "good" | "needs_improvement",
    "examples": string[]
  },
  "customer_emotion": {
    "positive_ratio": number,
    "detected_keywords": { "positive": string[], "negative": string[] },
    "judgment": "excellent" | "good" | "needs_improvement"
  },
  "concern_keywords": string[],
  "proposal_timing": {
    "detected_at": string,
    "proposed_at": string,
    "delay_seconds": number,
    "judgment": "excellent" | "good" | "needs_improvement"
  },
  "proposal_quality": {
    "benefit_ratio": number,
    "judgment": "excellent" | "good" | "needs_improvement",
    "examples": { "benefit": string[], "spec": string[] }
  },
  "conversion": {
    "likely_purchased": boolean,
    "evidence": string
  },
  "overall_score": number,  // 0-100
  "good_points": string[],
  "improvement_points": string[],
  "action_items": string[]  // 次回への具体的アクション3つ
}
`
    }]
  });
  
  return JSON.parse(analysis.content[0].text);
}
```

### 4.5 成功事例マッチング（ベクトル検索）

成功事例の類似検索には2つの選択肢を用意。Supabaseを既に利用しているため、pgvectorをメインとし、大規模スケール時にQdrantを検討。

#### 4.5.1 ベクトル検索オプション比較

| 項目 | **Supabase pgvector（推奨）** | Qdrant |
|------|------------------------------|--------|
| **特徴** | PostgreSQL拡張、既存DBに統合 | 専用ベクトルDB |
| **追加コスト** | **0円**（Supabase Pro含む） | $95/月〜（約1.5万円〜） |
| **運用負荷** | **低**（追加サービス不要） | 中（別サービス管理） |
| **推奨規模** | 〜10万件（十分） | 100万件以上 |
| **インデックス** | HNSW, IVFFlat対応 | HNSW |
| **フィルタ検索** | SQL WHERE句で柔軟 | 専用フィルタ構文 |
| **学習コスト** | **低**（SQL知識で対応） | 中（専用構文習得） |

**出典：**
- Supabase Docs「AI & Vectors」: https://supabase.com/docs/guides/ai
- Supabase Docs「pgvector」: https://supabase.com/docs/guides/database/extensions/pgvector

#### 4.5.2 Supabase pgvector（推奨オプション）

**メリット：**
- **追加コストゼロ**: 既存Supabase Pro Plan内で利用可能
- **シンプルな構成**: 別サービス不要、PostgreSQL内で完結
- **SQLで操作**: 慣れ親しんだSQLで類似検索が可能
- **RLSと統合**: Row Level Securityでデータ分離も自動適用

**美容室システムでの想定規模：**
- 成功事例: 〜5万件（十分なカバレッジ）
- pgvectorの推奨範囲（〜10万件）に収まる

```sql
-- 成功事例テーブル作成（pgvector使用）
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE success_cases (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  salon_id UUID NOT NULL REFERENCES salons(id),
  concern_keywords TEXT[] NOT NULL,          -- 悩みキーワード
  customer_age_group TEXT,                    -- 年代
  successful_talk TEXT NOT NULL,              -- 成功トーク全文
  key_tactics TEXT[],                         -- 成功要因
  conversion_rate FLOAT NOT NULL,             -- 成約率
  embedding VECTOR(1536) NOT NULL,            -- OpenAI text-embedding-3-small
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- HNSWインデックス作成（高速検索用）
CREATE INDEX ON success_cases 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Row Level Security（店舗データ分離）
ALTER TABLE success_cases ENABLE ROW LEVEL SECURITY;

CREATE POLICY "店舗データ分離" ON success_cases
FOR ALL USING (salon_id = (auth.jwt()->>'salon_id')::uuid);
```

```sql
-- 類似成功事例検索関数
CREATE OR REPLACE FUNCTION match_success_cases(
  query_embedding VECTOR(1536),
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 5,
  min_conversion_rate FLOAT DEFAULT 0.3
)
RETURNS TABLE (
  id UUID,
  concern_keywords TEXT[],
  successful_talk TEXT,
  key_tactics TEXT[],
  conversion_rate FLOAT,
  similarity FLOAT
)
LANGUAGE sql STABLE
AS $$
  SELECT 
    success_cases.id,
    success_cases.concern_keywords,
    success_cases.successful_talk,
    success_cases.key_tactics,
    success_cases.conversion_rate,
    1 - (success_cases.embedding <=> query_embedding) AS similarity
  FROM success_cases
  WHERE 
    1 - (success_cases.embedding <=> query_embedding) > match_threshold
    AND conversion_rate >= min_conversion_rate
  ORDER BY success_cases.embedding <=> query_embedding ASC
  LIMIT match_count;
$$;
```

```typescript
// TypeScript: 成功事例の検索
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

async function findSimilarSuccessCases(
  concernKeywords: string[],
  customerProfile: { age_group: string; visit_frequency: string }
): Promise<SuccessCase[]> {
  
  // 現在のシーンをテキスト化
  const sceneDescription = `
    お客様の悩み: ${concernKeywords.join(', ')}
    年代: ${customerProfile.age_group}
    来店頻度: ${customerProfile.visit_frequency}
  `;
  
  // OpenAI Embeddingでベクトル化
  const embeddingResponse = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: sceneDescription
  });
  const embedding = embeddingResponse.data[0].embedding;
  
  // Supabase pgvectorで類似検索（RPC経由）
  const { data, error } = await supabase.rpc('match_success_cases', {
    query_embedding: embedding,
    match_threshold: 0.7,
    match_count: 5,
    min_conversion_rate: 0.3
  });
  
  if (error) throw error;
  
  return data.map(row => ({
    case_id: row.id,
    similarity: row.similarity,
    concern: row.concern_keywords,
    successful_talk: row.successful_talk,
    conversion_rate: row.conversion_rate,
    key_tactics: row.key_tactics
  }));
}
```

#### 4.5.3 Qdrant（大規模スケール時の代替オプション）

成功事例が10万件を超える大規模展開時には、専用ベクトルDBであるQdrantへの移行を検討。

**Qdrantを選択する場合：**
- 成功事例10万件以上
- より高速なベクトル検索が必要
- 複雑なフィルタリング要件

```typescript
// Qdrant使用時の実装例（大規模スケール時）
import { QdrantClient } from '@qdrant/js-client-rest';

const qdrant = new QdrantClient({ url: QDRANT_URL, apiKey: QDRANT_API_KEY });

async function findSimilarSuccessCasesQdrant(
  concernKeywords: string[],
  customerProfile: CustomerProfile
): Promise<SuccessCase[]> {
  
  const sceneDescription = `
    お客様の悩み: ${concernKeywords.join(', ')}
    年代: ${customerProfile.age_group}
  `;
  
  const embedding = await generateEmbedding(sceneDescription);
  
  // Qdrantで類似検索
  const searchResults = await qdrant.search('success-cases', {
    vector: embedding,
    limit: 5,
    filter: {
      must: [
        { key: 'conversion_rate', range: { gte: 0.3 } }
      ]
    }
  });
  
  return searchResults.map(result => ({
    case_id: result.id,
    similarity: result.score,
    concern: result.payload.concern,
    successful_talk: result.payload.successful_talk,
    conversion_rate: result.payload.conversion_rate,
    key_tactics: result.payload.key_tactics
  }));
}
```

#### 4.5.4 ベクトル検索コスト比較

| オプション | 月額コスト | 推奨規模 | 移行タイミング |
|-----------|-----------|---------|---------------|
| **Supabase pgvector** | **0円**（Pro含む） | 〜10万件 | 初期版〜中規模 |
| **Qdrant Cloud** | $95〜/月（約1.5万円〜） | 10万件〜 | 大規模展開時 |

**推奨戦略：**
- 第1〜3フェーズ: Supabase pgvector（コスト最適化）
- 第4フェーズ以降: 成功事例10万件超えたらQdrant検討

### 4.6 セキュリティ・プライバシー設計

| 対策 | 実装内容 |
|------|---------|
| **データ最小化** | 音声は文字起こし後即座に破棄、テキストのみ保存 |
| **個人情報匿名化** | 名前・電話番号・住所を自動マスキング |
| **アクセス制御** | Supabase RLSによる店舗単位のデータ分離 |
| **暗号化** | 通信: TLS 1.3、保存: AES-256 |
| **データ保持期間** | 6年（法的要件に準拠）、以後自動削除 |

```sql
-- Row Level Security (RLS) ポリシー
-- 店舗は自店舗のデータのみアクセス可能

ALTER TABLE transcripts ENABLE ROW LEVEL SECURITY;

CREATE POLICY "店舗データ分離" ON transcripts
FOR ALL USING (
  salon_id = (auth.jwt()->>'salon_id')::uuid
);

-- 個人情報マスキング関数
CREATE OR REPLACE FUNCTION anonymize_text(input_text TEXT)
RETURNS TEXT AS $$
BEGIN
  RETURN regexp_replace(
    regexp_replace(
      regexp_replace(input_text, 
        '[一-龯ぁ-んァ-ヶー]{2,4}(さん|様|氏)', '○○様', 'g'),
      '\d{2,4}-\d{2,4}-\d{4}', '***-****-****', 'g'),
    '\d{3}-\d{4}', '***-****', 'g'
  );
END;
$$ LANGUAGE plpgsql;
```

---
